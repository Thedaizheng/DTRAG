# import json
# from rag.kdb.doc_handler import base
# import openai
# import os
#
#
# class Formatter(base.BaseDocHandler):
#     def run(self, sess: base.Session):
#         if sess.text == "":
#             return
#
#         client = openai.OpenAI(api_key=os.getenv("api_key"))
#         chat_completion = client.chat.completions.create(
#             messages=[{
#                 "role": "user",
#                 "content": self.get_prompt(sess.text)
#             }],
#             model=os.getenv("gpt_model"),
#             stream=False,
#             response_format={"type": "json_object"}
#         )
#
#         rs = json.loads(chat_completion.choices[0].message.content)
#         print(rs)
#         for one in rs["data"]:
#             phones = one.get("phone")
#             # åˆ¤æ–­æ˜¯å¦æœ‰éœ€è¦å¤„ç†çš„æ•æ„Ÿæ‰‹æœºå·
#             if phones is not None and len(phones) > 0:
#                 for one_phone in phones:
#                     one["content"] = one["content"].replace(
#                         one_phone, self.mask_phone_number(one_phone))
#
#         sess.text_formatted = rs["data"]
#
#     def mask_phone_number(self, phone):
#         masked_phone = phone[:3] + "****" + phone[7:]
#         return masked_phone
#
#     def get_prompt(self, content):
#         response_format = {
#             "data": [
#                 {
#                     "id": "intå‹ï¼Œå”¯ä¸€ID",
#                     "level": "intå‹ï¼Œå±‚çº§",
#                     "parent_id": "intå‹ï¼Œçˆ¶èŠ‚ç‚¹idï¼Œå¦‚æœæ²¡æœ‰çˆ¶èŠ‚ç‚¹åˆ™å–å€¼-1",
#                     "seq_index": "intå‹ï¼Œå¦‚æœæ˜¯åŒä¸€å±‚çº§ä¸”åŒä¸€çˆ¶çº§ï¼Œåˆ™è¯¥ä»£è¡¨è¯­å¥é¡ºåºindexï¼Œä»1å¼€å§‹",
#                     "content": "å†…å®¹",
#                     "phone": "æ•°ç»„ï¼Œæ–‡æœ¬ä¸­å‡ºç°çš„æ‰‹æœºå·"
#                 }
#             ]
#         }
#
#         response_format_str = json.dumps(response_format)
#
#         return f'''
# # Role
# - ä½ æ˜¯ä¸€ä¸ªæ–‡æ¡£å¤„ç†åŠ©æ‰‹ï¼Œä½ éœ€è¦æŒ‰ç…§æ–‡æ¡£å«ä¹‰å°†æ–‡æ¡£åˆ†æˆçˆ¶å­ç»“æ„
# ## Attention
# - åªå¼•ç”¨å†…å®¹ï¼Œä¸è¦æ”¹å˜æ–‡æ¡£çš„å†…å®¹
# - åˆ†å±‚åçš„å†…å®¹çš„åˆé›†å¯¹æ¯”åŸå§‹æ–‡æœ¬ï¼Œä¸è¦å‡ºç°æ–‡æœ¬ä¸¢å¤±
# ## WorkFlow
# - å…ˆæŒ‰ç…§è¯­ä¹‰å°†æ–‡æ¡£è¿›è¡Œåˆ†æ®µï¼Œæ¯æ®µå†…å®¹è¯­ä¹‰è¦å†…èš
# - åœ¨åŸºäºåˆ†æ®µçš„å†…å®¹è¿›è¡Œä»å±å…³ç³»çš„åˆ’åˆ†
# - æ‰¾åˆ°æ®µè½ä¸­å¯èƒ½ä¼šå‡ºç°çš„æ‰‹æœºå·å¹¶æ ‡è¯†å‡ºæ¥
# - æ–‡æœ¬ä¸­çš„æ‰€æœ‰æ–‡å­—éƒ½è¦è¢«åˆ†ä¸ºçˆ¶å­ç»“æ„ï¼Œä¸è¦é—æ¼ä»»ä½•çš„æ–‡å­—
# - è¯·ä»…è¾“å‡ºæ ‡å‡† JSON æ ¼å¼ï¼Œç¡®ä¿æ‰€æœ‰å±æ€§åç”¨åŒå¼•å· " åŒ…è£¹ï¼Œæ— éœ€æ·»åŠ å…¶ä»–è¯´æ˜ã€‚
# ## Task
# - åˆ†æ """{content}"""
# ## JSON
# - """{response_format_str}"""
# ## Init
# - åšä¸º<Role>ï¼Œä¸¥æ ¼éµå®ˆ<Attention>ï¼Œå¹¶ä¾ç…§<WorkFlow>å»å®Œæˆ<Task>ï¼Œå¹¶ä»¥<JSON>æ–¹å¼è¾“å‡º
# '''


import json
import re
import os
import json5
from openai import OpenAI
from sentence_transformers import SentenceTransformer
from sklearn.cluster import AgglomerativeClustering
from sklearn.metrics.pairwise import cosine_similarity
from rag.kdb.doc_handler import base


class Formatter(base.BaseDocHandler):
    def run(self, sess: base.Session):
        """
        ä¸»æµç¨‹ï¼š
        1. ä½¿ç”¨ OpenAI æ¨¡å‹è¿›è¡Œè¯­ä¹‰åˆ†å—ï¼›
        2. è‡ªåŠ¨è¯†åˆ«æ‰‹æœºå·å¹¶è„±æ•ï¼›
        3. æ„å»ºå±‚æ¬¡ç»“æ„ï¼›
        4. è¾“å‡ºæ ‡å‡†ç»“æ„åŒ– JSONã€‚
        """
        if not sess.text:
            print("âš ï¸ æ— è¾“å…¥æ–‡æœ¬ï¼Œè·³è¿‡å¤„ç†ã€‚")
            return

        # ===== Step 1: è°ƒç”¨ OpenAI æ¨¡å‹åˆ†å— =====
        client = OpenAI(base_url = "http://chatapi.littlewheat.com/v1",api_key=os.getenv("api_key"))
        print("ğŸ§  æ­£åœ¨è°ƒç”¨ OpenAI æ¨¡å‹è¿›è¡Œè¯­ä¹‰åˆ†å— ...")

        chat_completion = client.chat.completions.create(
            messages=[{"role": "user", "content": self.get_prompt(sess.text)}],
            model=os.getenv("gpt_model"),
            stream=False,
            response_format={"type": "json_object"}
        )

        raw_content = chat_completion.choices[0].message.content.strip()
        rs = self._clean_json(raw_content)
        blocks = rs.get("data", [])
        if not blocks:
            raise ValueError("âš ï¸ æ¨¡å‹æœªè¿”å›æœ‰æ•ˆ data æ•°æ®")

        print(f"âœ… æ¨¡å‹è¯­ä¹‰åˆ†å—å®Œæˆï¼Œå…± {len(blocks)} ä¸ªè¯­ä¹‰å—ã€‚")

        # ===== Step 2: æ‰‹æœºå·è„±æ• =====
        for one in blocks:
            phones = one.get("phone", [])
            if phones:
                for phone in phones:
                    one["content"] = one["content"].replace(
                        phone, self.mask_phone_number(phone)
                    )

        # ===== Step 3: æ„å»ºå±‚æ¬¡æ ‘ç»“æ„ =====
        tree_data = self._build_tree(blocks)
        sess.text_formatted = tree_data
        print("ğŸ¯ æ–‡æ¡£æ ¼å¼åŒ–å®Œæˆï¼")

    # =========================================================
    #   å±‚æ¬¡èšç±»æ„å»ºæ ‘
    # =========================================================
    def _build_tree(self, blocks):
        """
        ä½¿ç”¨ SentenceTransformer + å±‚æ¬¡èšç±»æ„å»ºæ ‘çŠ¶ç»“æ„ã€‚
        """
        model_path = r"E:\DTRAG\models\bge-large-zh-v1.5"
        model = self._ensure_local_bge_model(model_path)

        texts = [b["content"] for b in blocks if b.get("content")]
        if not texts:
            raise ValueError("âŒ æ— æœ‰æ•ˆæ–‡æœ¬å—å†…å®¹ï¼")

        print("ğŸ” æ­£åœ¨ç”Ÿæˆæ–‡æœ¬ embedding ...")
        embeddings = model.encode(texts, normalize_embeddings=True)
        sim_matrix = cosine_similarity(embeddings)
        distance_matrix = 1 - sim_matrix

        print("ğŸŒ³ æ­£åœ¨æ‰§è¡Œå±‚æ¬¡èšç±» ...")
        try:
            clustering = AgglomerativeClustering(
                metric="precomputed",
                linkage="average",
                distance_threshold=0.3,
                n_clusters=None
            )
            clustering.fit(distance_matrix)
        except Exception as e:
            print(f"âš ï¸ èšç±»å¤±è´¥ï¼Œä½¿ç”¨çº¿æ€§å±‚çº§å›é€€ã€‚é”™è¯¯: {e}")
            clustering = None

        # ===== ç”Ÿæˆæ ‘èŠ‚ç‚¹ =====
        nodes = []
        next_id = 1
        for i, blk in enumerate(blocks):
            nodes.append({
                "id": next_id,
                "level": blk.get("level", 1),
                "parent_id": blk.get("parent_id", -1),
                "seq_index": blk.get("seq_index", i + 1),
                "content": blk.get("content", ""),
                "phone": blk.get("phone", [])
            })
            next_id += 1

        if clustering is None:
            return nodes

        labels = clustering.labels_
        cluster_dict = {}
        for idx, label in enumerate(labels):
            cluster_dict.setdefault(label, []).append(idx)

        cluster_ids = sorted(cluster_dict.keys())
        for cluster_id in cluster_ids:
            child_indices = cluster_dict[cluster_id]
            if len(child_indices) <= 1:
                continue

            parent_idx = child_indices[0]
            parent_node = nodes[parent_idx]
            parent_node["level"] = 1
            parent_node["parent_id"] = -1

            for j, child_idx in enumerate(child_indices[1:], start=1):
                nodes[child_idx]["level"] = 2
                nodes[child_idx]["parent_id"] = parent_node["id"]
                nodes[child_idx]["seq_index"] = j

        print(f"âœ… å±‚æ¬¡æ ‘æ„å»ºå®Œæˆï¼Œå…± {len(nodes)} ä¸ªèŠ‚ç‚¹ã€‚")
        return nodes

    # =========================================================
    #   è‡ªåŠ¨æ£€æµ‹å¹¶ä¸‹è½½æœ¬åœ° BGE æ¨¡å‹
    # =========================================================
    def _ensure_local_bge_model(self, model_path: str):
        """
        æ£€æŸ¥æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è‡ªåŠ¨ä¸‹è½½åˆ°è¯¥ç›®å½•ã€‚
        """
        if not os.path.exists(model_path):
            print("âš™ï¸ æ£€æµ‹åˆ°æœ¬åœ°æ¨¡å‹ä¸å­˜åœ¨ï¼Œæ­£åœ¨ä» HuggingFace ä¸‹è½½â€¦â€¦")
            model = SentenceTransformer("BAAI/bge-large-zh-v1.5")
            os.makedirs(model_path, exist_ok=True)
            model.save(model_path)
            print(f"âœ… æ¨¡å‹å·²ä¸‹è½½å¹¶ä¿å­˜è‡³: {model_path}")
        else:
            print(f"âœ… æ£€æµ‹åˆ°æœ¬åœ°æ¨¡å‹ï¼Œç›´æ¥åŠ è½½: {model_path}")
            model = SentenceTransformer(model_path)
        return model

    # =========================================================
    #   ç¨³å¥ JSON è§£æï¼ˆæ”¯æŒ JSON5 / Markdown åŒ…è£¹ï¼‰
    # =========================================================
    def _clean_json(self, raw_content: str) -> dict:
        for loader in (json, json5):
            try:
                return loader.loads(raw_content)
            except Exception:
                pass

        cleaned = re.sub(r"^```[a-zA-Z]*", "", raw_content)
        cleaned = re.sub(r"```$", "", cleaned)
        cleaned = cleaned.strip()

        match = re.search(r'\{[\s\S]*\}', cleaned)
        if match:
            json_str = match.group(0)
            for loader in (json, json5):
                try:
                    return loader.loads(json_str)
                except Exception:
                    continue

        path = os.path.join(os.getcwd(), "debug_raw_output.json")
        with open(path, "w", encoding="utf-8") as f:
            f.write(raw_content)
        raise ValueError(f"âŒ JSONè§£æå¤±è´¥ï¼ŒåŸå§‹è¾“å‡ºå·²ä¿å­˜è‡³: {path}")

    # =========================================================
    #   æ‰‹æœºå·è„±æ•
    # =========================================================
    def mask_phone_number(self, phone: str) -> str:
        if len(phone) >= 11:
            return phone[:3] + "****" + phone[7:]
        return phone

    # =========================================================
    #   æç¤ºè¯æ„é€ 
    # =========================================================
    def get_prompt(self, content: str) -> str:
        response_format = {
            "data": [
                {
                    "id": "intå‹ï¼Œå”¯ä¸€ID",
                    "level": "intå‹ï¼Œå±‚çº§",
                    "parent_id": "intå‹ï¼Œçˆ¶èŠ‚ç‚¹idï¼Œå¦‚æœæ²¡æœ‰çˆ¶èŠ‚ç‚¹åˆ™å–å€¼-1",
                    "seq_index": "intå‹ï¼ŒåŒå±‚çº§é¡ºåºï¼Œä»1å¼€å§‹",
                    "content": "å†…å®¹",
                    "phone": "æ•°ç»„ï¼Œæ–‡æœ¬ä¸­å‡ºç°çš„æ‰‹æœºå·"
                }
            ]
        }

        response_format_str = json.dumps(response_format, ensure_ascii=False)
        return f'''
ä½ æ˜¯ä¸€ä¸ªæ–‡æ¡£ç»“æ„åŒ–åŠ©æ‰‹ï¼Œè¯·æ ¹æ®è¯­ä¹‰å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œåˆ†æ®µå’Œåˆ†å±‚ã€‚
è¦æ±‚ï¼š
1. æ‰€æœ‰å†…å®¹éƒ½å¿…é¡»è¢«åˆ’åˆ†åˆ°ä¸€ä¸ªèŠ‚ç‚¹ä¸­ï¼Œä¸å¾—é—æ¼ï¼›
2. æŒ‰è¯­ä¹‰å±‚çº§ç»„ç»‡ï¼Œçˆ¶å­å±‚å…³ç³»æ¸…æ™°ï¼›
3. æ£€æµ‹å¹¶æå–æ‰€æœ‰æ‰‹æœºå·ï¼›
4. ä¸¥æ ¼è¾“å‡ºæ ‡å‡† JSONï¼Œæ— å…¶ä»–è¯´æ˜æ–‡å­—ã€‚

è¾“å‡ºæ ¼å¼ï¼š
{response_format_str}

æ–‡æ¡£å†…å®¹å¦‚ä¸‹ï¼š
{content}
'''
