# import json
# import re
# import os
# import json5   # âœ… æ–°å¢ï¼šå®½æ¾ JSON è§£æ
# from rag.kdb.doc_handler import base
# from openai import OpenAI
#
#
# class Formatter(base.BaseDocHandler):
#     def run(self, sess: base.Session):
#         if not sess.text:
#             return
#
#         client = OpenAI(
#             api_key=os.getenv("DEEPSEEK_API_KEY"),
#             base_url="https://api.deepseek.com"
#         )
#
#         chat_completion = client.chat.completions.create(
#             messages=[{"role": "user", "content": self.get_prompt(sess.text)}],
#             model=os.getenv("DEEPSEEK_MODEL"),
#             stream=False,
#             response_format={"type": "json_object"}  # âœ… å°½é‡è¦æ±‚ JSON
#         )
#
#         raw_content = chat_completion.choices[0].message.content.strip()
#
#         # ======= æ¸…æ´— JSON =======
#         rs = self._clean_json(raw_content)
#
#         # ======= æ‰‹æœºå·è„±æ• =======
#         for one in rs.get("data", []):
#             phones = one.get("phone")
#             if phones:
#                 for one_phone in phones:
#                     one["content"] = one["content"].replace(
#                         one_phone, self.mask_phone_number(one_phone)
#                     )
#
#         sess.text_formatted = rs["data"]
#
#     # =========================================================
#     #   JSON è§£æå¢å¼ºç‰ˆ
#     # =========================================================
#     def _clean_json(self, raw_content: str) -> dict:
#         """
#         ç¨³å¥ JSON è§£ææµç¨‹ï¼š
#         1. å°è¯•æ ‡å‡† json.loads
#         2. å°è¯• json5.loads
#         3. æ¸…æ´— markdown/ä»£ç å— + æ­£åˆ™æå– {...}
#         4. å†æ¬¡ç”¨ json/json5 å°è¯•
#         """
#         # Step 1: ç›´æ¥å°è¯•æ ‡å‡† JSON
#         try:
#             return json.loads(raw_content)
#         except Exception:
#             pass
#
#         # Step 2: å°è¯• json5ï¼ˆå®¹å¿å•å¼•å·ã€å°¾é€—å·ç­‰ï¼‰
#         try:
#             return json5.loads(raw_content)
#         except Exception:
#             pass
#
#         # Step 3: æ¸…æ´— markdown ä»£ç å—ç¬¦å·
#         cleaned = re.sub(r"^```[a-zA-Z]*", "", raw_content)
#         cleaned = re.sub(r"```$", "", cleaned)
#         cleaned = cleaned.strip()
#
#         # Step 4: æ­£åˆ™æå–ç¬¬ä¸€ä¸ª {...}
#         match = re.search(r'\{[\s\S]*\}', cleaned)
#         if match:
#             json_str = match.group(0)
#
#             # å°è¯•æ ‡å‡† JSON
#             try:
#                 return json.loads(json_str)
#             except Exception:
#                 pass
#
#             # å°è¯• json5
#             try:
#                 return json5.loads(json_str)
#             except Exception:
#                 pass
#
#             # æœ€åå°è¯•ç®€å•ä¿®å¤ï¼ˆå°¾é€—å·ã€æ¢è¡Œï¼‰
#             json_str = re.sub(r",\s*([}\]])", r"\1", json_str)
#             json_str = json_str.replace("\n", "\\n")
#             try:
#                 return json.loads(json_str)
#             except Exception:
#                 try:
#                     return json5.loads(json_str)
#                 except Exception as e:
#                     return self._save_and_raise(raw_content, e)
#
#         # å®Œå…¨å¤±è´¥ï¼Œä¿å­˜åŸå§‹è¾“å‡º
#         return self._save_and_raise(raw_content, "æœªåŒ¹é…åˆ° JSON å¯¹è±¡")
#
#     def _save_and_raise(self, raw_content: str, err):
#         path = os.path.join(os.getcwd(), "debug_raw_output.json")
#         with open(path, "w", encoding="utf-8") as f:
#             f.write(raw_content)
#         raise ValueError(f"âŒ JSONè§£æå¤±è´¥: {err}, å·²ä¿å­˜åŸå§‹è¾“å‡º: {path}")
#
#     # =========================================================
#     #   å…¶ä»–å·¥å…·å‡½æ•°
#     # =========================================================
#     def mask_phone_number(self, phone: str) -> str:
#         if len(phone) >= 11:
#             return phone[:3] + "****" + phone[7:]
#         return phone
#
#     def get_prompt(self, content: str) -> str:
#         """
#         å¼ºåŒ–æç¤ºè¯ï¼Œç¡®ä¿ DeepSeek è¾“å‡ºåªå« JSONï¼Œä¸å¸¦é¢å¤–æ–‡å­—
#         """
#         response_format = {
#             "data": [
#                 {
#                     "id": "intå‹ï¼Œå”¯ä¸€ID",
#                     "level": "intå‹ï¼Œå±‚çº§",
#                     "parent_id": "intå‹ï¼Œçˆ¶èŠ‚ç‚¹idï¼Œå¦‚æœæ²¡æœ‰çˆ¶èŠ‚ç‚¹åˆ™å–å€¼-1",
#                     "seq_index": "intå‹ï¼Œå¦‚æœæ˜¯åŒä¸€å±‚çº§ä¸”åŒä¸€çˆ¶çº§ï¼Œåˆ™è¯¥ä»£è¡¨è¯­å¥é¡ºåºindexï¼Œä»1å¼€å§‹",
#                     "content": "å†…å®¹",
#                     "phone": "æ•°ç»„ï¼Œæ–‡æœ¬ä¸­å‡ºç°çš„æ‰‹æœºå·"
#                 }
#             ]
#         }
#         response_format_str = json.dumps(response_format, ensure_ascii=False)
#
#         return f"""
#         ä½ æ˜¯ä¸€ä¸ªæ–‡æ¡£å¤„ç†åŠ©æ‰‹ã€‚ä»»åŠ¡ï¼šå°†ä»¥ä¸‹æ–‡æ¡£åˆ’åˆ†ä¸ºçˆ¶å­ç»“æ„ï¼Œå¹¶æ ‡è¯†æ–‡æœ¬ä¸­çš„æ‰‹æœºå·ã€‚
#
#         è¯·ä¸¥æ ¼æŒ‰ç…§ JSON è¾“å‡ºï¼Œä¸å…è®¸ä»»ä½•é¢å¤–æ–‡æœ¬ã€æ³¨é‡Šæˆ–è§£é‡Šã€‚
#
#         æ–‡æ¡£å†…å®¹ï¼š
#         {content}
#
#         è¾“å‡º JSON æ ¼å¼ï¼š
#         {response_format_str}
#
#         è¦æ±‚ï¼š
#         - ä¸éœ€è¦é€å­—é€å¥æ‹†åˆ†ï¼Œå¯ä»¥æŒ‰æ®µè½æˆ–é€»è¾‘å•å…ƒè¿›è¡Œåˆ’åˆ†
#         - æ¯ä¸ªçˆ¶èŠ‚ç‚¹ä¸‹çš„å­èŠ‚ç‚¹ä¸è¶…è¿‡ 10 ä¸ª
#         - æœ€å¤§å±‚çº§æ·±åº¦é™åˆ¶ä¸º 3
#         - æ‰€æœ‰å±æ€§åå¿…é¡»ç”¨åŒå¼•å· ""
#         - è¾“å‡ºå¿…é¡»æ˜¯ä¸¥æ ¼å¯è§£æçš„ JSON
#         - åªè¾“å‡º JSON
#         """


import json
import re
import os
import json5
import numpy as np
from sklearn.cluster import AgglomerativeClustering
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer
from rag.kdb.doc_handler import base
from openai import OpenAI


class Formatter(base.BaseDocHandler):
    def run(self, sess: base.Session):
        """
        æ„å»ºç¬¦åˆ DTRAG æ¶æ„çš„å±‚æ¬¡çŸ¥è¯†ç»“æ„ï¼š
        1. è°ƒç”¨ LLM å¯¹æ–‡æœ¬è¿›è¡Œè¯­ä¹‰åˆ†å—ï¼›
        2. åŸºäº embedding å±‚æ¬¡èšç±»æ„å»ºæ ‘ç»“æ„ï¼›
        3. è¾“å‡ºç»“æ„åŒ– JSONï¼ˆåŒ…å« idã€parent_idã€levelã€seq_indexã€contentã€phoneï¼‰ã€‚
        """
        if not sess.text:
            print("âš ï¸ æ— è¾“å…¥æ–‡æœ¬ï¼Œè·³è¿‡å¤„ç†ã€‚")
            return

        # ===== Step 1: è°ƒç”¨ DeepSeek LLM åˆ†å— =====
        client = OpenAI(
            api_key=os.getenv("DEEPSEEK_API_KEY"),
            base_url="https://api.deepseek.com"
        )

        print("ğŸ§  æ­£åœ¨è°ƒç”¨ DeepSeek æ¨¡å‹è¿›è¡Œè¯­ä¹‰åˆ†å— ...")
        chat_completion = client.chat.completions.create(
            messages=[{"role": "user", "content": self.get_prompt(sess.text)}],
            model=os.getenv("DEEPSEEK_MODEL"),
            stream=False,
            response_format={"type": "json_object"}
        )

        raw_content = chat_completion.choices[0].message.content.strip()
        rs = self._clean_json(raw_content)
        blocks = rs.get("blocks", [])
        if not blocks:
            raise ValueError("âš ï¸ æ¨¡å‹æœªè¿”å›æœ‰æ•ˆ blocks æ•°æ®")

        print(f"âœ… åˆ†å—å®Œæˆï¼Œå…± {len(blocks)} ä¸ªè¯­ä¹‰å—ã€‚")

        # ===== Step 2: æ„å»ºå±‚æ¬¡æ ‘ç»“æ„ =====
        tree_data = self._build_tree(blocks)

        # ===== Step 3: æ‰‹æœºå·è„±æ• =====
        for node in tree_data:
            for phone in node.get("phone", []):
                node["content"] = node["content"].replace(
                    phone, self.mask_phone_number(phone)
                )

        sess.text_formatted = tree_data
        print("ğŸ¯ æ ¼å¼åŒ–å®Œæˆï¼")

    # =========================================================
    #   å±‚æ¬¡èšç±»æ„å»ºæ ‘
    # =========================================================
    def _build_tree(self, blocks):
        """
        ä½¿ç”¨å±‚æ¬¡èšç±»ç®—æ³•æ„å»º Document Tree:
        1. ä½¿ç”¨ SentenceTransformer è®¡ç®—æ¯ä¸ªæ–‡æœ¬å— embeddingï¼›
        2. åŸºäº cosine ç›¸ä¼¼åº¦è®¡ç®—è·ç¦»çŸ©é˜µï¼›
        3. æ‰§è¡Œå±‚æ¬¡èšç±»ï¼›
        4. å°†èšç±»å±‚æ¬¡æ˜ å°„ä¸ºæ ‘ç»“æ„ã€‚
        """
        # === ä½ çš„å›ºå®šæ¨¡å‹å­˜æ”¾ç›®å½• ===
        model_path = r"E:\DTRAG\models\bge-large-zh-v1.5"
        model = self._ensure_local_bge_model(model_path)

        texts = [b["content"] for b in blocks if b.get("content")]
        if not texts:
            raise ValueError("âŒ æ— æœ‰æ•ˆæ–‡æœ¬å—å†…å®¹ï¼")

        print("ğŸ” æ­£åœ¨ç”Ÿæˆæ–‡æœ¬ embedding ...")
        embeddings = model.encode(texts, normalize_embeddings=True)
        sim_matrix = cosine_similarity(embeddings)
        distance_matrix = 1 - sim_matrix

        print("ğŸŒ³ æ­£åœ¨æ‰§è¡Œå±‚æ¬¡èšç±» ...")
        try:
            clustering = AgglomerativeClustering(
                metric="precomputed",
                linkage="average",
                distance_threshold=0.3,
                n_clusters=None
            )
            clustering.fit(distance_matrix)
        except Exception as e:
            print(f"âš ï¸ èšç±»å¤±è´¥ï¼Œä½¿ç”¨é¡ºåºå±‚çº§å›é€€ã€‚é”™è¯¯: {e}")
            clustering = None

        # ===== ç”ŸæˆèŠ‚ç‚¹ç»“æ„ =====
        nodes = []
        next_id = 1
        for i, blk in enumerate(blocks):
            nodes.append({
                "id": next_id,
                "level": 1,
                "parent_id": -1,
                "seq_index": i + 1,
                "content": blk.get("content", ""),
                "phone": blk.get("phones", [])
            })
            next_id += 1

        if clustering is None:
            return nodes

        labels = clustering.labels_
        cluster_dict = {}
        for idx, label in enumerate(labels):
            cluster_dict.setdefault(label, []).append(idx)

        cluster_ids = sorted(cluster_dict.keys())
        for cluster_id in cluster_ids:
            child_indices = cluster_dict[cluster_id]
            if len(child_indices) <= 1:
                continue

            parent_idx = child_indices[0]
            parent_node = nodes[parent_idx]
            parent_node["level"] = 1
            parent_node["parent_id"] = -1

            for j, child_idx in enumerate(child_indices[1:], start=1):
                nodes[child_idx]["level"] = 2
                nodes[child_idx]["parent_id"] = parent_node["id"]
                nodes[child_idx]["seq_index"] = j

        for node in nodes:
            node["level"] = min(node["level"], 3)

        print(f"âœ… å±‚æ¬¡æ ‘æ„å»ºå®Œæˆï¼Œå…± {len(nodes)} ä¸ªèŠ‚ç‚¹ã€‚")
        return nodes

    # =========================================================
    #   è‡ªåŠ¨æ£€æµ‹ + ä¸‹è½½æœ¬åœ°æ¨¡å‹
    # =========================================================
    def _ensure_local_bge_model(self, model_path: str):
        """
        æ£€æŸ¥æœ¬åœ°æ˜¯å¦å­˜åœ¨ BGE æ¨¡å‹ï¼›
        å¦‚æœä¸å­˜åœ¨ï¼Œåˆ™è‡ªåŠ¨ä» HuggingFace ä¸‹è½½å¹¶ä¿å­˜åˆ°è¯¥ç›®å½•ã€‚
        """
        if not os.path.exists(model_path):
            print("âš™ï¸ æ£€æµ‹åˆ°æœ¬åœ°æ¨¡å‹ä¸å­˜åœ¨ï¼Œæ­£åœ¨ä» HuggingFace ä¸‹è½½â€¦â€¦")
            model = SentenceTransformer("BAAI/bge-large-zh-v1.5")
            os.makedirs(model_path, exist_ok=True)
            model.save(model_path)
            print(f"âœ… æ¨¡å‹å·²ä¸‹è½½å¹¶ä¿å­˜è‡³: {model_path}")
        else:
            print(f"âœ… æ£€æµ‹åˆ°æœ¬åœ°æ¨¡å‹ï¼Œç›´æ¥åŠ è½½: {model_path}")
            model = SentenceTransformer(model_path)
        return model

    # =========================================================
    #   JSON è§£æå¢å¼ºç‰ˆ
    # =========================================================
    def _clean_json(self, raw_content: str) -> dict:
        """
        ç¨³å¥çš„ JSON è§£æï¼Œæ”¯æŒæ ‡å‡† JSON / JSON5 / Markdown åŒ…è£¹ã€‚
        """
        for loader in (json, json5):
            try:
                return loader.loads(raw_content)
            except Exception:
                pass

        cleaned = re.sub(r"^```[a-zA-Z]*", "", raw_content)
        cleaned = re.sub(r"```$", "", cleaned)
        cleaned = cleaned.strip()

        match = re.search(r'\{[\s\S]*\}', cleaned)
        if match:
            json_str = match.group(0)
            for loader in (json, json5):
                try:
                    return loader.loads(json_str)
                except Exception:
                    continue

        return self._save_and_raise(raw_content, "æœªåŒ¹é…åˆ° JSON å¯¹è±¡")

    def _save_and_raise(self, raw_content: str, err):
        path = os.path.join(os.getcwd(), "debug_raw_output.json")
        with open(path, "w", encoding="utf-8") as f:
            f.write(raw_content)
        raise ValueError(f"âŒ JSONè§£æå¤±è´¥: {err}, å·²ä¿å­˜åŸå§‹è¾“å‡º: {path}")

    # =========================================================
    #   æ‰‹æœºå·è„±æ•
    # =========================================================
    def mask_phone_number(self, phone: str) -> str:
        if len(phone) >= 11:
            return phone[:3] + "****" + phone[7:]
        return phone

    # =========================================================
    #   æç¤ºè¯ï¼šä»…åšè¯­ä¹‰åˆ†å—
    # =========================================================
    def get_prompt(self, content: str) -> str:
        """
        æ¨¡å‹ä»…è´Ÿè´£è¯­ä¹‰åˆ†å—ï¼Œä¸å†æ„é€ å±‚çº§ç»“æ„ã€‚
        """
        response_format = {
            "blocks": [
                {
                    "content": "é€»è¾‘å®Œæ•´çš„æ–‡æœ¬æ®µè½",
                    "phones": "æ•°ç»„ï¼Œæ–‡æœ¬ä¸­å‡ºç°çš„æ‰‹æœºå·"
                }
            ]
        }
        response_format_str = json.dumps(response_format, ensure_ascii=False)
        return f"""
ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†æ–‡æ¡£ç»“æ„åˆ†æåŠ©æ‰‹ã€‚è¯·å°†ä»¥ä¸‹æ–‡æœ¬åˆ’åˆ†ä¸ºè‹¥å¹²è¯­ä¹‰å®Œæ•´çš„é€»è¾‘å•å…ƒï¼ˆå³æ®µè½çº§çŸ¥è¯†å—ï¼‰ï¼Œ
æ¯ä¸ªå—åº”è¡¨è¾¾ç›¸å¯¹ç‹¬ç«‹çš„ä¸»é¢˜ã€‚è¯·æ£€æµ‹å¹¶æå–æ–‡æœ¬ä¸­å‡ºç°çš„æ‰‹æœºå·ã€‚

è¯·ä¸¥æ ¼è¾“å‡ºä»¥ä¸‹ JSON ç»“æ„ï¼ˆä¸åŒ…å«é¢å¤–è¯´æ˜æ–‡å­—ï¼‰ï¼š
{response_format_str}

æ–‡æ¡£å†…å®¹å¦‚ä¸‹ï¼š
{content}
"""


